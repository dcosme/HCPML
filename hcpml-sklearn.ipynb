{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Can we predict individual differences in behavior from brain activity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Developed at Neurohackweek 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HCPML_plt import clfAccHist\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import multiprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the data on disk\n",
    "datapath = os.path.abspath('/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the task and parameter estimate files to run\n",
    "task = 'WM' # working memory task\n",
    "pe_list = ['9','10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/105216\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/105620\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/105923\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/106016\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/106319\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/106521\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/106824\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/107220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n",
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/107321\n",
      "/Users/kevinsitek/Dropbox (MIT)/projects/nhw17/hcp_data_sample/107422\n"
     ]
    }
   ],
   "source": [
    "sub_list=[] # subject index list\n",
    "pe_bin_list=[] # list of (binarized) PEs\n",
    "\n",
    "# add each subject to the data array\n",
    "for sx, subpath in enumerate(glob.glob(datapath+'/*')):    \n",
    "    print subpath\n",
    "    # for each of the two contrasts\n",
    "    for cx,pe in enumerate(pe_list):\n",
    "        sub_list.append(sx+1) # save the subject index to a subject list\n",
    "        pe_bin_list.append(cx) # save the (binarized) PE to a PE list\n",
    "        \n",
    "        # load the parameter estimates\n",
    "        fpath = os.path.join(subpath, 'MNINonLinear/Results/tfMRI_%s/'%task,\n",
    "                             'tfMRI_%s_hp200_s2_level2.feat/GrayordinatesStats/'%task,\n",
    "                             'cope%s.feat/pe1.dtseries.nii'%(pe))\n",
    "        pe1 = nib.load(fpath)\n",
    "        \n",
    "        # reshape the data into a 2-D array\n",
    "        sub_pe_data = np.array(pe1.get_data().reshape(pe1.get_data().shape[4:]))\n",
    "        \n",
    "        # add the parameter estimate data to the overall data matrix\n",
    "        if not sx and not cx:\n",
    "            group_data = sub_pe_data\n",
    "        else:\n",
    "            group_data = np.concatenate((group_data, sub_pe_data),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 91282)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pe_bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (91282, 20)\n",
      "y shape:  20\n"
     ]
    }
   ],
   "source": [
    "print 'x shape: ', group_data.T.shape\n",
    "print 'y shape: ', len(pe_bin_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for a master holdout test data set\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(group_data, pe_bin_list, \n",
    "                                                test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the model\n",
    "svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model on the training data\n",
    "svc.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# predict the labels of the test data\n",
    "prediction = svc.predict(Xtest)\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "model accuracy:  0.3\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of the model's predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Ytest, prediction))\n",
    "\n",
    "print \"model accuracy: \", svc.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier algorithm\n",
    "if clf_type is 'SVM':\n",
    "    clf = LinearCSVMC()\n",
    "elif clf_type is 'KNN':\n",
    "    clf = kNN(k=knn_k, voting='weighted')\n",
    "#cross-validation algorithm\n",
    "if cv_type is 'split_half':\n",
    "    cv = CrossValidation(clf,\n",
    "                         HalfPartitioner(count=2,\n",
    "                                         selection_strategy='random', attr='subject'),\n",
    "                         errorfx=mean_match_accuracy)\n",
    "elif cv_type is 'LOSO':\n",
    "    cv = CrossValidation(clf,\n",
    "                         NFoldPartitioner(attr='subject'),\n",
    "                         errorfx=mean_match_accuracy)\n",
    "elif cv_type is 'nfld':\n",
    "    cv = CrossValidation(clf,\n",
    "                         NFoldPartitioner(count=5,\n",
    "                                         selection_strategy='random', attr='subject'),\n",
    "                         errorfx=mean_match_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert feature weights to numpy array and save\n",
    "sens_out = np.asarray(sens)\n",
    "np.save(os.path.join(out_path,'cv_results',\n",
    "                     '%dsubs_%s_CV_%s_ftrWghts'%(nsubs, cv_type, clf_type)),\n",
    "        sens_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
